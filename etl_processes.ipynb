{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline - Smart Building IoT Sensors\n",
    "\n",
    "## Casus\n",
    "We gaan data verwerken van temperatuur- en CO2-sensoren in een universiteitskantoor. De sensoren sturen metingen naar verschillende bronnen:\n",
    "- **Lokale JSON files** (batch uploads van sensoren)\n",
    "- **CSV metadata** (sensor configuratie)\n",
    "- **Publieke API** (weer data voor correlatie)\n",
    "\n",
    "**Doel**: Inzicht krijgen in kantoorklimaat en energiebesparing mogelijk maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benodigde libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9acff",
   "metadata": {},
   "source": [
    "## 1. Trigger - Hoe en wanneer start de pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "In productie zou dit een scheduled job zijn (bijv. via cron/Airflow).\n",
    "\n",
    "**1.1 Cron expression oefening**: \n",
    "\n",
    "Wat is de cron expression voor “elke werkdag om 0:00 uur”\n",
    "\n",
    "\n",
    "```\n",
    "* * * * *\n",
    "┬ ┬ ┬ ┬ ┬\n",
    "│ │ │ │ └─── Day of week (0-6 or SUN-SAT)\n",
    "│ │ │ └────── Month (1-12 or JAN-DEC)\n",
    "│ │ └───────── Day of month (1-31)\n",
    "│ └────────────Hour (0-23)\n",
    "└─────────────── Minute (0-59)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Schrijf hier het antwoord op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87233760",
   "metadata": {},
   "source": [
    "**1.2 Op job completion oefening**:\n",
    "\n",
    "Als je zeker wilt weten dat een job (B) pas begint als de vorige (A) klaar is, kan je dat doen met APScheduler.\n",
    "\n",
    "Vraag: wat gebeurt er als je de `if` statement verwijdert in `on_done()`:\n",
    "```\n",
    "def on_done(event):\n",
    "    sched.add_job(b, id=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90180173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from apscheduler.events import EVENT_JOB_EXECUTED\n",
    "import time\n",
    "\n",
    "def a(): \n",
    "    print(\"Job A started...\")\n",
    "    time.sleep(2)\n",
    "    print(\"A done.\")\n",
    "\n",
    "def b(): \n",
    "    print(\"Job B started after A...\")\n",
    "    time.sleep(1)\n",
    "    print(\"B done.\")\n",
    "\n",
    "def on_done(event):\n",
    "    if event.job_id == \"a\": \n",
    "        sched.add_job(b, id=\"b\")\n",
    "\n",
    "sched = BackgroundScheduler()\n",
    "sched.add_job(a, id=\"a\")\n",
    "sched.add_listener(on_done, EVENT_JOB_EXECUTED)\n",
    "\n",
    "# Start de scheduler\n",
    "sched.start()\n",
    "time.sleep(5)\n",
    "sched.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ee1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vul hier je antwoord in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdad63",
   "metadata": {},
   "source": [
    "**1.3 Zoek JSON files** \n",
    "\n",
    "Controleer of er .json files bestaan in FOLDER_NAME (zie hieronder), met `Path()` en `glob()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb15688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes worden gedefinieerd in hoofdletters\n",
    "FOLDER_NAME = \"sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c32050",
   "metadata": {},
   "source": [
    "**1.4 Maak een functie**\n",
    "\n",
    "Bij oefening 1.2 heb je ze al gezien: functies. Functies maken het mogelijk een stukje code te hergebruiken. De syntax is: \n",
    "```\n",
    "def functie_naam(parameter_naam: <type> = default_waarde):\n",
    "    <logica>\n",
    "    return <object>\n",
    "```\n",
    "\n",
    "Bijvoorbeeld:\n",
    "```\n",
    "def add(x: int, y: int):\n",
    "    result = x + y\n",
    "    return result\n",
    "```\n",
    "\n",
    "Stappen:\n",
    "- Maak een functie `check_for_data()` dat op basis van een folder name de json files returnt.\n",
    "- Roep de functie aan en sla het return object op in een variabele `files_to_process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83abf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Connection - Hoe verbindt de source met de target?\n",
    "\n",
    "We hebben 3 verschillende databronnen voor deze oefening:\n",
    "1. Lokale JSON files (sensor readings)\n",
    "2. CSV file (sensor metadata)\n",
    "3. Publieke API (Open-Meteo voor weer data)\n",
    "\n",
    "In productie:\n",
    "- Authentication (API token, OAuth2, service account)\n",
    "- Credentials in environment variables (NOOIT in code!)\n",
    "- Retry logic voor netwerkfouten\n",
    "\n",
    "**2.1 Haal weather data op met publieke API Open-Meteo**\n",
    "\n",
    "Test eerst of de API werkt, en daarna verpak je het weer in een functie `request_weather(latitude: int, longitude: int, date: str)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18504855",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROTTERDAM_COORDINATES = (51.92, 4.47) # Latitude, Longitude\n",
    "TEST_DATE = \"2025-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96804d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API details\n",
    "base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": date,\n",
    "        \"end_date\": date,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m\",\n",
    "        \"timezone\": \"Europe/Amsterdam\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. State Management - Hoe houd je bij wat er is veranderd?\n",
    "\n",
    "Definieer 2 functies:\n",
    "- `load_state()`, dat de laatste pipeline status inlaadt, of initialiseert bij de eerste keer\n",
    "- `save_state()`, voor als de pipeline klaar is, om de status te updaten.\n",
    "\n",
    "Sla op welke files al verwerkt zijn en de timestamp van de laatste run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_FILE = \"pipeline_state.json\"\n",
    "\n",
    "def load_state():\n",
    "    \"\"\"Laad de laatste pipeline state\"\"\"\n",
    "    try:\n",
    "        with open(STATE_FILE, 'r') as f:\n",
    "            state = json.load(f)\n",
    "            print(f\"State geladen: laatste run op {state['last_run']}\")\n",
    "            print(f\"Verwerkte files: {len(state['processed_files'])}\")\n",
    "            return state\n",
    "    except FileNotFoundError:\n",
    "        print(\"Geen eerdere state gevonden, start vanaf nu\")\n",
    "        return {\n",
    "            \"last_run\": None,\n",
    "            \"records_processed\": 0,\n",
    "            \"processed_files\": []\n",
    "        }\n",
    "\n",
    "def save_state(state):\n",
    "    \"\"\"Bewaar de huidige pipeline state\"\"\"\n",
    "    with open(STATE_FILE, 'w') as f:\n",
    "        json.dump(state, f, indent=2)\n",
    "    print(\"State opgeslagen\")\n",
    "\n",
    "# Load current state\n",
    "pipeline_state = load_state()\n",
    "\n",
    "# Filter nieuwe files (die nog niet verwerkt zijn)\n",
    "new_files = [f for f in files_to_process if f.name not in pipeline_state['processed_files']]\n",
    "print(f\"\\nNieuwe files om te verwerken: {len(new_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Data Extraction - Hoe extraheer je de data?\n",
    "\n",
    "Haal data op uit 3 verschillende bronnen (batch processing).\n",
    "\n",
    "We hebben 3 verschillende databronnen:\n",
    "1. JSON files (sensor readings)\n",
    "2. CSV file (sensor metadata)\n",
    "3. Publieke API (Open-Meteo voor weer data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7e214",
   "metadata": {},
   "source": [
    "**4.1 Interpreteer onderstaande functie om JSONs in te laden**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. JSON files\n",
    "def extract_sensor_data(json_files):\n",
    "    \"\"\"Lees sensor readings uit JSON files\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Gelezen: {file_path.name} ({len(data)} records)\")\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d337d77",
   "metadata": {},
   "source": [
    "**4.2 Maak de functie af**\n",
    "\n",
    "Lees de metadata CSV en return het als een pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe91373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CSV file\n",
    "def extract_sensor_metadata(csv_file=\"sample_data/sensor_metadata.csv\"):\n",
    "    \"\"\"Lees sensor metadata uit CSV\"\"\"\n",
    "    NotImplemented\n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9bb34",
   "metadata": {},
   "source": [
    "**BONUS** \n",
    "\n",
    "Implementeer de functie `extract_weather_data_for_dates()` die een dictionary returnt, obv dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f97a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publieke API (Open-Meteo voor weer data)\n",
    "def extract_weather_data_for_dates(dates):\n",
    "    \"\"\"Haal uurlijkse weer data op voor alle unieke datums in de sensor data\"\"\"\n",
    "    weather_by_hour = {}\n",
    "    NotImplemented\n",
    "    return weather_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a099f1",
   "metadata": {},
   "source": [
    "Nu kunnen we alle 3 de databronnen met de bovenstaande functies ophalen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb408be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ophalen van alle sensor databronnen\n",
    "raw_sensor_data = extract_sensor_data(new_files if new_files else files_to_process[:1]) # files_to_process komt uit oefening 1.4\n",
    "sensor_metadata = extract_sensor_metadata()\n",
    "\n",
    "# Voorbeelden\n",
    "print(f\"Voorbeeld ruwe data:\")\n",
    "print(json.dumps(raw_sensor_data[:2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2b320",
   "metadata": {},
   "source": [
    "Uit de sensor data weten we welke data relevant zijn voor de weer API, en kunnen we specifiek voor die dagen weather data ophalen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bepaal unieke datums uit sensor data\n",
    "df_temp = pd.DataFrame(raw_sensor_data)\n",
    "df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "unique_dates = df_temp['timestamp'].dt.date.unique()\n",
    "print(f\"\\nUnieke datums in sensor data: {len(unique_dates)}\")\n",
    "\n",
    "# Ophalen van de weer databron\n",
    "weather_by_hour = extract_weather_data_for_dates(unique_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Transformation - Moet je filteren, omvormen voordat data naar target gaat?\n",
    "\n",
    "Transformeer en verrijk de data\n",
    "\n",
    "**5.1 Combineer de sensormetingen met de sensor metadata**\n",
    "\n",
    "Selecteer alleen de kolommen die relevant zijn\n",
    "\n",
    "Hulpmiddelen:\n",
    "- `df.merge()`\n",
    "- Selecteer meerdere kolommen met `[[kolommen]]`, bijv. `df[[\"sensor_id\", \"sensor_type\"]]`, let op dubbele haakjes (`[[`)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30186138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf9e0d",
   "metadata": {},
   "source": [
    "**5.2 Combineer de sensor data (DataFrame) met de weer data (dictionary)**\n",
    "\n",
    "\n",
    "Hulpmiddelen:\n",
    "- De weather data was afgerond op het uur, weet je nog? Match daarom de sensor timestamp ook naar het dichtstbijzijnde uur:\n",
    "\n",
    "  `df['timestamp_hour'] = df['timestamp'].dt.floor('h').dt.strftime('%Y-%m-%dT%H:%M')`\n",
    "\n",
    "- Gebruik map() om voor elke rij een .get() functie aan te roepen in de weer dictionary\n",
    "\n",
    "  `df['outdoor_temp'] = df['timestamp_hour'].map(lambda h: weather_by_hour.get(h, {}).get('outdoor_temp'))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7ed08",
   "metadata": {},
   "source": [
    "**5.3 Huiswerkopdracht**\n",
    "\n",
    "1. Voeg afgeleide kolommen toe: hour_of_day, day_of_week, is_working_hours\n",
    "2. Filter onrealistische waarden voor temperatuur en CO2\n",
    "3. Geef een waarschuwing als een meting met lage batterij is gevonden\n",
    "4. Meer interessante verrijkingen die je zelf kunt bedenken!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f43b4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Validation and Data Quality - Hoe zorg je ervoor dat je data correct is?\n",
    "\n",
    "**6 Voer data quality checks uit voordat we data opslaan. Wat is je tolerantieniveau?**\n",
    "\n",
    "- Check 1: Geen null waarden in kritieke kolommen\n",
    "- Check 2: Duplicaten\n",
    "- Check 3: Data coverage - elke sensor heeft data?\n",
    "- Check 4: Waarde ranges per sensor type\n",
    "- Check 5: Tijdsgaten (missende metingen)\n",
    "\n",
    "Tot slot:\n",
    "- Print rapport\n",
    "- Sla resultaat van kritische checks op in variabele is_valid (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Data Loading - Waar en hoe sla je de data op?\n",
    "\n",
    "**7. Sla de data op naar CSV en Parquet bestanden als de validatie van eerder was geslaagd**\n",
    "\n",
    "**Parquet vs CSV:**\n",
    "- CSV: Row-based, makkelijk leesbaar, groot\n",
    "- Parquet: Column-based, gecomprimeerd, snel voor analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. Archiving and Retention - Hoe lang bewaar je data?\n",
    "\n",
    "**8. Implementeer een retention policy: verwijder data ouder dan X dagen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Pipeline Afronden - Update State\n",
    "\n",
    "Sla de nieuwe pipeline state op voor de volgende run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementeer hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. Check nieuwe state\n",
    "Run nu nog een keer de code van het blok \"3. State Management\" en je ziet dat er geen nieuwe files meer te verwerken zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Extra Opdrachten voor studenten\n",
    "\n",
    "### Basis opdrachten:\n",
    "1. **Trigger**: Pas de trigger aan zodat deze alleen JSON files van vandaag verwerkt\n",
    "2. **Extraction**: Voeg een extra sensor type toe aan de sample data (bijv. luchtvochtigheid)\n",
    "3. **Transformation**: Bereken het gemiddelde per sensor per uur\n",
    "4. **Validation**: Voeg een validatie toe die checkt of batterijniveau niet te laag is (<10%)\n",
    "\n",
    "### Gevorderde opdrachten:\n",
    "5. **Error handling**: Implementeer retry logic voor de API call (probeer 3x met exponential backoff)\n",
    "6. **Monitoring**: Voeg logging toe die bijhoudt hoelang elke stap duurt\n",
    "7. **Alerting**: Stuur een waarschuwing als CO2 > 1000 ppm EN tijdens werktijd\n",
    "\n",
    "### Uitdagingen:\n",
    "9. **Data enrichment**: Voeg postcode gegevens toe op basis van locatie\n",
    "10. **Schaalvergroting**: Wat als je 100+ JSON files per dag krijgt? Hoe optimaliseer je?\n",
    "11. **Data governance**: Implementeer data lineage - track voor elke record waar het vandaan komt\n",
    "12. **ETLT**: Welke transformaties zou bovenop het huidige resultaat willen doen? Voeg deze toe.\n",
    "13. **Real-time**: Simuleer een streaming scenario: verwerk elke 30 seconden nieuwe data\n",
    "14. **Parquet partitioning**: Sla Parquet data op gepartitioneerd per dag voor betere query performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
