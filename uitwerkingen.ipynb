{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline - Smart Building IoT Sensors\n",
    "\n",
    "## Casus\n",
    "We gaan data verwerken van temperatuur- en CO2-sensoren in een universiteitskantoor. De sensoren sturen metingen naar verschillende bronnen:\n",
    "- **Lokale JSON files** (batch uploads van sensoren)\n",
    "- **CSV metadata** (sensor configuratie)\n",
    "- **Publieke API** (weer data voor correlatie)\n",
    "\n",
    "**Doel**: Inzicht krijgen in kantoorklimaat en energiebesparing mogelijk maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benodigde libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trigger - Hoe en wanneer start de pipeline?\n",
    "\n",
    "In productie zou dit een scheduled job zijn (bijv. via cron/Airflow).\n",
    "\n",
    "**1.1 Cron expression oefening**\n",
    "\n",
    "Hoe zou je een cron expression schrijven voor elke werkdag om 00:00?\n",
    "```\n",
    "* * * * *\n",
    "┬ ┬ ┬ ┬ ┬\n",
    "│ │ │ │ └─── Day of week (0-6 or SUN-SAT)\n",
    "│ │ │ └────── Month (1-12 or JAN-DEC)\n",
    "│ │ └───────── Day of month (1-31)\n",
    "│ └────────────Hour (0-23)\n",
    "└─────────────── Minute (0-59)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 0 * * 1-5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"0 0 * * 1-5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Op job completion oefening**:\n",
    "\n",
    "Als je zeker wilt weten dat een job (B) pas begint als de vorige (A) klaar is, kan je dat doen met APScheduler.\n",
    "\n",
    "Vraag: wat gebeurt er als je de `if` statement verwijdert in `on_done()`:\n",
    "```\n",
    "def on_done(event):\n",
    "    sched.add_job(b, id=\"b\")\n",
    "```\n",
    "in plaats van \n",
    "```\n",
    "def on_done(event):\n",
    "    if event.job_id == \"a\": \n",
    "        sched.add_job(b, id=\"b\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dan zou job B ook uitgevoerd worden als job B klaar is, en dus oneindig doorgaan.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Dan zou job B ook uitgevoerd worden als job B klaar is, en dus oneindig doorgaan.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Zoek JSON files** \n",
    "\n",
    "Controleer of er json files bestaan in FOLDER_NAME, met `Path()` en `glob()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"sample_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 Maak een functie**\n",
    "\n",
    "Stappen:\n",
    "- Maak een functie `check_for_data()` dat op basis van een folder name de json files returnt.\n",
    "- Roep de functie aan en sla het return object op in een variabele `files_to_process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline getriggerd om 14:43:36\n",
      "Gevonden: 2 JSON files in sample_data/\n",
      "Data beschikbaar, pipeline start!\n",
      "  - sensor_readings_day2.json\n",
      "  - sensor_readings_day1.json\n"
     ]
    }
   ],
   "source": [
    "def check_for_data(data_dir=\"sample_data\"):\n",
    "    \"\"\"Check of er JSON files zijn om te verwerken\"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    json_files = list(data_path.glob(\"*.json\"))\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    print(f\"Pipeline getriggerd om {current_time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"Gevonden: {len(json_files)} JSON files in {data_dir}/\")\n",
    "    \n",
    "    return json_files\n",
    "\n",
    "# Test de trigger\n",
    "files_to_process = check_for_data()\n",
    "if files_to_process:\n",
    "    print(\"Data beschikbaar, pipeline start!\")\n",
    "    for f in files_to_process:\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connection - Hoe verbindt de source met de target?\n",
    "\n",
    "We hebben 3 verschillende databronnen voor deze oefening:\n",
    "1. Lokale JSON files (sensor readings)\n",
    "2. CSV file (sensor metadata)\n",
    "3. Publieke API (Open-Meteo voor weer data)\n",
    "\n",
    "In productie:\n",
    "- Authentication (API token, OAuth2, service account)\n",
    "- Credentials in environment variables (NOOIT in code!)\n",
    "- Retry logic voor netwerkfouten\n",
    "\n",
    "**2.1 Haal weather data op met publieke API Open-Meteo**\n",
    "\n",
    "Test eerst of de API werkt, en daarna verpak je het weer in een functie `request_weather(latitude: int, longitude: int, date: str)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROTTERDAM_COORDINATES = (51.92, 4.47)\n",
    "TEST_DATE = \"2025-10-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather on 2025-10-01: 11.0°C, 94% humidity\n"
     ]
    }
   ],
   "source": [
    "# Simpel:\n",
    "def request_weather(latitude: int, longitude: int, date: str):\n",
    "    base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": date,\n",
    "        \"end_date\": date,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m\",\n",
    "        \"timezone\": \"Europe/Amsterdam\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "weather_data = request_weather(ROTTERDAM_COORDINATES[0], ROTTERDAM_COORDINATES[1], TEST_DATE)\n",
    "\n",
    "print(f\"Weather on {TEST_DATE}: {weather_data['hourly']['temperature_2m'][0]}°C, {weather_data['hourly']['relative_humidity_2m'][0]}% humidity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uurlijkse data voor 2025-10-01:\n",
      "  Eerste uur (00:00): 11.0°C, 94%\n",
      "  Totaal 24 uur beschikbaar\n"
     ]
    }
   ],
   "source": [
    "# Complexer met error handling en keuze endpoint\n",
    "\n",
    "def request_weather(lat_long_coordinates: tuple, date: str):\n",
    "    \"\"\"Connect naar Open-Meteo API voor uurlijkse weer data\"\"\"\n",
    "    # Parse date string en vergelijk met vandaag\n",
    "    request_date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    today = datetime.now().date()\n",
    "    \n",
    "    # Kies juiste endpoint: archive voor verleden, forecast voor vandaag/toekomst\n",
    "    if request_date < today:\n",
    "        base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    else:\n",
    "        base_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        \n",
    "    params = {\n",
    "        \"latitude\": lat_long_coordinates[0],\n",
    "        \"longitude\": lat_long_coordinates[1],\n",
    "        \"start_date\": date,\n",
    "        \"end_date\": date,\n",
    "        \"hourly\": \"temperature_2m,relative_humidity_2m\",\n",
    "        \"timezone\": \"Europe/Amsterdam\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request gefaald: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test API connection\n",
    "weather_data = request_weather(ROTTERDAM_COORDINATES, TEST_DATE)\n",
    "if weather_data and 'hourly' in weather_data:\n",
    "    print(f\"Uurlijkse data voor {TEST_DATE}:\")\n",
    "    print(f\"  Eerste uur (00:00): {weather_data['hourly']['temperature_2m'][0]}°C, {weather_data['hourly']['relative_humidity_2m'][0]}%\")\n",
    "    print(f\"  Totaal {len(weather_data['hourly']['time'])} uur beschikbaar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. State Management - Hoe houd je bij wat er is veranderd?\n",
    "\n",
    "Definieer 2 functies:\n",
    "- `load_state()`, dat de laatste pipeline status inlaadt, of initialiseert bij de eerste keer\n",
    "- `save_state()`, voor als de pipeline klaar is, om de status te updaten.\n",
    "\n",
    "Sla op welke files al verwerkt zijn en de timestamp van de laatste run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State geladen: laatste run op 2025-10-17T00:13:12.400471\n",
      "Verwerkte files: 2\n",
      "\n",
      "Nieuwe files om te verwerken: 0\n"
     ]
    }
   ],
   "source": [
    "STATE_FILE = \"pipeline_state.json\"\n",
    "\n",
    "def load_state():\n",
    "    \"\"\"Laad de laatste pipeline state\"\"\"\n",
    "    try:\n",
    "        with open(STATE_FILE, 'r') as f:\n",
    "            state = json.load(f)\n",
    "            print(f\"State geladen: laatste run op {state['last_run']}\")\n",
    "            print(f\"Verwerkte files: {len(state['processed_files'])}\")\n",
    "            return state\n",
    "    except FileNotFoundError:\n",
    "        print(\"Geen eerdere state gevonden, start vanaf nu\")\n",
    "        return {\n",
    "            \"last_run\": None,\n",
    "            \"records_processed\": 0,\n",
    "            \"processed_files\": []\n",
    "        }\n",
    "\n",
    "def save_state(state):\n",
    "    \"\"\"Bewaar de huidige pipeline state\"\"\"\n",
    "    with open(STATE_FILE, 'w') as f:\n",
    "        json.dump(state, f, indent=2)\n",
    "    print(\"State opgeslagen\")\n",
    "\n",
    "# Load current state\n",
    "pipeline_state = load_state()\n",
    "\n",
    "# Filter nieuwe files (die nog niet verwerkt zijn)\n",
    "new_files = [f for f in files_to_process if f.name not in pipeline_state['processed_files']]\n",
    "print(f\"\\nNieuwe files om te verwerken: {len(new_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Extraction - Hoe extraheer je de data?\n",
    "\n",
    "Haal data op uit 3 verschillende bronnen (batch processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gelezen: sensor_readings_day2.json (21 records)\n",
      "Metadata geladen: 3 sensoren\n",
      "Voorbeeld ruwe data:\n",
      "[\n",
      "  {\n",
      "    \"sensor_id\": \"TEMP_001\",\n",
      "    \"timestamp\": \"2025-10-15T08:00:00\",\n",
      "    \"value\": 19.2,\n",
      "    \"unit\": \"celsius\",\n",
      "    \"location\": \"room_A101\",\n",
      "    \"battery_level\": 83\n",
      "  },\n",
      "  {\n",
      "    \"sensor_id\": \"TEMP_002\",\n",
      "    \"timestamp\": \"2025-10-15T08:00:00\",\n",
      "    \"value\": 20.8,\n",
      "    \"unit\": \"celsius\",\n",
      "    \"location\": \"room_B203\",\n",
      "    \"battery_level\": 88\n",
      "  }\n",
      "]\n",
      "\n",
      "Unieke datums in sensor data: 2\n",
      "Weer data voor 2025-10-15: 24 uur opgehaald\n"
     ]
    }
   ],
   "source": [
    "from pandas import NaT\n",
    "\n",
    "def extract_sensor_data(json_files):\n",
    "    \"\"\"Lees sensor readings uit JSON files\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "            print(f\"Gelezen: {file_path.name} ({len(data)} records)\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def extract_sensor_metadata(csv_file=\"sample_data/sensor_metadata.csv\"):\n",
    "    \"\"\"Lees sensor metadata uit CSV\"\"\"\n",
    "    metadata_df = pd.read_csv(csv_file)\n",
    "    print(f\"Metadata geladen: {len(metadata_df)} sensoren\")\n",
    "    return metadata_df\n",
    "\n",
    "def extract_weather_data_for_dates(dates):\n",
    "    \"\"\"Haal uurlijkse weer data op voor alle unieke datums in de sensor data\"\"\"\n",
    "    weather_by_hour = {}\n",
    "    \n",
    "    for date in dates:\n",
    "        if isinstance(date, type(NaT)):\n",
    "            continue\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        weather_data = request_weather(ROTTERDAM_COORDINATES, date_str)\n",
    "        \n",
    "        if weather_data and 'hourly' in weather_data:\n",
    "            # Converteer naar dict met timestamp als key\n",
    "            for i, timestamp in enumerate(weather_data['hourly']['time']):\n",
    "                weather_by_hour[timestamp] = {\n",
    "                    \"outdoor_temp\": weather_data['hourly']['temperature_2m'][i],\n",
    "                    \"outdoor_humidity\": weather_data['hourly']['relative_humidity_2m'][i]\n",
    "                }\n",
    "            print(f\"Weer data voor {date_str}: {len(weather_data['hourly']['time'])} uur opgehaald\")\n",
    "    \n",
    "    return weather_by_hour\n",
    "\n",
    "# Extract data uit alle bronnen\n",
    "raw_sensor_data = extract_sensor_data(new_files if new_files else files_to_process[:1])\n",
    "sensor_metadata = extract_sensor_metadata()\n",
    "\n",
    "# Voorbeelden\n",
    "print(f\"Voorbeeld ruwe data:\")\n",
    "print(json.dumps(raw_sensor_data[:2], indent=2))\n",
    "\n",
    "# Bepaal unieke datums uit sensor data\n",
    "df_temp = pd.DataFrame(raw_sensor_data)\n",
    "df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "unique_dates = df_temp['timestamp'].dt.date.unique()\n",
    "print(f\"\\nUnieke datums in sensor data: {len(unique_dates)}\")\n",
    "\n",
    "# Ophalen van de weer databron\n",
    "weather_by_hour = extract_weather_data_for_dates(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sensor_id           timestamp  value     unit   location  battery_level  \\\n",
      "0  TEMP_001 2025-10-15 08:00:00   19.2  celsius  room_A101             83   \n",
      "1  TEMP_002 2025-10-15 08:00:00   20.8  celsius  room_B203             88   \n",
      "2   CO2_001 2025-10-15 08:00:00  410.0      ppm  hallway_C             74   \n",
      "3  TEMP_001 2025-10-15 09:00:00   21.1  celsius  room_A101             83   \n",
      "4  TEMP_002 2025-10-15 09:00:00   22.9  celsius  room_B203             88   \n",
      "\n",
      "  sensor_type    manufacturer   model  outdoor_temp  humidity  \n",
      "0        TEMP      SensorCorp  TC-500          12.4      94.0  \n",
      "1        TEMP      SensorCorp  TC-500          12.4      94.0  \n",
      "2         CO2  AirQuality Inc  AQ-200          12.4      94.0  \n",
      "3        TEMP      SensorCorp  TC-500          12.6      94.0  \n",
      "4        TEMP      SensorCorp  TC-500          12.6      94.0  \n"
     ]
    }
   ],
   "source": [
    "result = df_temp.merge(sensor_metadata[['sensor_id', 'sensor_type', 'manufacturer', 'model']], on=\"sensor_id\", how=\"left\")\n",
    "# weather_by_hour\n",
    "result['timestamp'] = pd.to_datetime(result['timestamp'])\n",
    "result[\"timestamp_hour\"] = result['timestamp'].dt.floor('h').dt.strftime('%Y-%m-%dT%H:%M')\n",
    "result[\"outdoor_temp\"] = result['timestamp_hour'].map(lambda h: weather_by_hour.get(h, {}).get('outdoor_temp'))\n",
    "result[\"humidity\"] = result['timestamp_hour'].map(lambda h: weather_by_hour.get(h, {}).get('outdoor_humidity'))\n",
    "result = result.drop(columns=[\"timestamp_hour\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformation - Moet je filteren, omvormen voordat data naar target gaat?\n",
    "\n",
    "Transformeer en verrijk de data:\n",
    "- Join sensor readings met metadata\n",
    "- Voeg weather context toe\n",
    "- Bereken afgeleide velden\n",
    "- Filter onrealistische waarden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "21 records getransformeerd\n",
      "2 onrealistische waarden verwijderd\n",
      "19 records behouden\n",
      "\n",
      "Getransformeerde data (eerste 6 rijen):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>location</th>\n",
       "      <th>battery_level</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>outdoor_temp</th>\n",
       "      <th>outdoor_humidity</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_working_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEMP_001</td>\n",
       "      <td>2025-10-15 08:00:00</td>\n",
       "      <td>19.2</td>\n",
       "      <td>celsius</td>\n",
       "      <td>room_A101</td>\n",
       "      <td>83</td>\n",
       "      <td>TEMP</td>\n",
       "      <td>SensorCorp</td>\n",
       "      <td>TC-500</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEMP_002</td>\n",
       "      <td>2025-10-15 08:00:00</td>\n",
       "      <td>20.8</td>\n",
       "      <td>celsius</td>\n",
       "      <td>room_B203</td>\n",
       "      <td>88</td>\n",
       "      <td>TEMP</td>\n",
       "      <td>SensorCorp</td>\n",
       "      <td>TC-500</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2_001</td>\n",
       "      <td>2025-10-15 08:00:00</td>\n",
       "      <td>410.0</td>\n",
       "      <td>ppm</td>\n",
       "      <td>hallway_C</td>\n",
       "      <td>74</td>\n",
       "      <td>CO2</td>\n",
       "      <td>AirQuality Inc</td>\n",
       "      <td>AQ-200</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEMP_001</td>\n",
       "      <td>2025-10-15 09:00:00</td>\n",
       "      <td>21.1</td>\n",
       "      <td>celsius</td>\n",
       "      <td>room_A101</td>\n",
       "      <td>83</td>\n",
       "      <td>TEMP</td>\n",
       "      <td>SensorCorp</td>\n",
       "      <td>TC-500</td>\n",
       "      <td>12.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEMP_002</td>\n",
       "      <td>2025-10-15 09:00:00</td>\n",
       "      <td>22.9</td>\n",
       "      <td>celsius</td>\n",
       "      <td>room_B203</td>\n",
       "      <td>88</td>\n",
       "      <td>TEMP</td>\n",
       "      <td>SensorCorp</td>\n",
       "      <td>TC-500</td>\n",
       "      <td>12.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CO2_001</td>\n",
       "      <td>2025-10-15 09:00:00</td>\n",
       "      <td>680.0</td>\n",
       "      <td>ppm</td>\n",
       "      <td>hallway_C</td>\n",
       "      <td>74</td>\n",
       "      <td>CO2</td>\n",
       "      <td>AirQuality Inc</td>\n",
       "      <td>AQ-200</td>\n",
       "      <td>12.6</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sensor_id           timestamp  value     unit   location  battery_level  \\\n",
       "0  TEMP_001 2025-10-15 08:00:00   19.2  celsius  room_A101             83   \n",
       "1  TEMP_002 2025-10-15 08:00:00   20.8  celsius  room_B203             88   \n",
       "2   CO2_001 2025-10-15 08:00:00  410.0      ppm  hallway_C             74   \n",
       "3  TEMP_001 2025-10-15 09:00:00   21.1  celsius  room_A101             83   \n",
       "4  TEMP_002 2025-10-15 09:00:00   22.9  celsius  room_B203             88   \n",
       "5   CO2_001 2025-10-15 09:00:00  680.0      ppm  hallway_C             74   \n",
       "\n",
       "  sensor_type    manufacturer   model  outdoor_temp  outdoor_humidity  \\\n",
       "0        TEMP      SensorCorp  TC-500          12.4              94.0   \n",
       "1        TEMP      SensorCorp  TC-500          12.4              94.0   \n",
       "2         CO2  AirQuality Inc  AQ-200          12.4              94.0   \n",
       "3        TEMP      SensorCorp  TC-500          12.6              94.0   \n",
       "4        TEMP      SensorCorp  TC-500          12.6              94.0   \n",
       "5         CO2  AirQuality Inc  AQ-200          12.6              94.0   \n",
       "\n",
       "   hour_of_day  day_of_week  is_working_hours  \n",
       "0          8.0          2.0              True  \n",
       "1          8.0          2.0              True  \n",
       "2          8.0          2.0              True  \n",
       "3          9.0          2.0              True  \n",
       "4          9.0          2.0              True  \n",
       "5          9.0          2.0              True  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_sensor_data(raw_data, metadata_df, weather_by_hour):\n",
    "    \"\"\"Transformeer en verrijk sensor data\"\"\"\n",
    "    # Converteer naar DataFrame\n",
    "    df = pd.DataFrame(raw_data)\n",
    "\n",
    "    # 1. Timestamp conversie\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # 2. Join met metadata\n",
    "    df = df.merge(metadata_df[['sensor_id', 'sensor_type', 'manufacturer', 'model']], \n",
    "                   on='sensor_id', how='left')\n",
    "\n",
    "    # 3. Voeg weer context toe per uur\n",
    "    # Match sensor timestamp naar dichtstbijzijnde uur voor weather data\n",
    "    if weather_by_hour:\n",
    "        df['timestamp_hour'] = df['timestamp'].dt.floor('h').dt.strftime('%Y-%m-%dT%H:%M')\n",
    "        df['outdoor_temp'] = df['timestamp_hour'].map(lambda h: weather_by_hour.get(h, {}).get('outdoor_temp'))\n",
    "        df['outdoor_humidity'] = df['timestamp_hour'].map(lambda h: weather_by_hour.get(h, {}).get('outdoor_humidity'))\n",
    "        df = df.drop(columns=['timestamp_hour'])    \n",
    "\n",
    "    # 4. Voeg afgeleide kolommen toe\n",
    "    df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['is_working_hours'] = df['hour_of_day'].between(8, 18) & df['day_of_week'].between(0, 4)\n",
    "\n",
    "    # 5. Filter onrealistische waarden (ETLT - filtering in extract fase)\n",
    "    df_clean = df[\n",
    "        ((df['sensor_type'] == 'TEMP') & (df['value'].between(MIN_TEMP, MAX_TEMP))) |\n",
    "        ((df['sensor_type'] == 'CO2') & (df['value'].between(300, 5000)))\n",
    "    ].copy()\n",
    "\n",
    "    # 6. Filter lage batterij (waarschuwing)\n",
    "    low_battery = df_clean[df_clean['battery_level'] < 20]\n",
    "    if len(low_battery) > 0:\n",
    "        print(f\"[WAARSCHUWING] {len(low_battery)} readings met lage batterij:\")\n",
    "        for _, row in low_battery.iterrows():\n",
    "            print(f\"  {row['sensor_id']} op {row['timestamp']}: {row['battery_level']}%\")\n",
    "    \n",
    "    removed = len(df) - len(df_clean)\n",
    "    print(f\"\\n{len(df)} records getransformeerd\")\n",
    "    print(f\"{removed} onrealistische waarden verwijderd\")\n",
    "    print(f\"{len(df_clean)} records behouden\")\n",
    "    \n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Transform\n",
    "transformed_data = transform_sensor_data(raw_sensor_data, sensor_metadata, weather_by_hour)\n",
    "print(\"\\nGetransformeerde data (eerste 6 rijen):\")\n",
    "transformed_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation and Data Quality - Hoe zorg je ervoor dat je data correct is?\n",
    "\n",
    "**6 Voer data quality checks uit voordat we data opslaan. Wat is je tolerantieniveau?**\n",
    "\n",
    "- Check 1: Geen null waarden in kritieke kolommen\n",
    "- Check 2: Duplicaten\n",
    "- Check 3: Data coverage - elke sensor heeft data?\n",
    "- Check 4: Waarde ranges per sensor type\n",
    "- Check 5: Tijdsgaten (missende metingen)\n",
    "\n",
    "Tot slot:\n",
    "- Print rapport\n",
    "- Sla resultaat van kritische checks op in variabele is_valid (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed_data[transformed_data.duplicated(subset=[\"sensor_id\", \"timestamp\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Rijen met null in 'timestamp':\n",
      "   sensor_id timestamp  value\n",
      "17   CO2_001       NaT  760.0\n",
      "\n",
      "============================================================\n",
      "DATA QUALITY RAPPORT\n",
      "============================================================\n",
      "\n",
      "[KRITIEKE ISSUES]\n",
      "  - Null waarden gevonden: {'timestamp': 1}\n",
      "\n",
      "[WAARSCHUWINGEN]\n",
      "  - 3 CO2 waarden > 1000 ppm (slechte luchtkwaliteit!)\n",
      "  - TEMP_001: 9 tijdsgaten > 1 uur\n",
      "  - TEMP_002: 9 tijdsgaten > 1 uur\n",
      "  - CO2_001: 8 tijdsgaten > 1 uur\n",
      "\n",
      "[INFO] Data AFGEKEURD\n",
      "Tolerantieniveau: geen kritieke issues toegestaan\n"
     ]
    }
   ],
   "source": [
    "def validate_data(df):\n",
    "    \"\"\"Valideer data kwaliteit en return quality rapport\"\"\"\n",
    "    issues = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Check 1: Geen null waarden in kritieke kolommen\n",
    "    critical_cols = ['sensor_id', 'timestamp', 'value']\n",
    "    null_counts = df[critical_cols].isnull().sum()\n",
    "    if null_counts.any():\n",
    "        issues.append(f\"Null waarden gevonden: {null_counts[null_counts > 0].to_dict()}\")\n",
    "        # Toon rijen met null waarden in kritieke kolommen\n",
    "        for col in critical_cols:\n",
    "            null_rows = df[df[col].isnull()]\n",
    "            if len(null_rows) > 0:\n",
    "                print(f\"\\n[DEBUG] Rijen met null in '{col}':\")\n",
    "                print(null_rows[critical_cols].to_string())\n",
    "    \n",
    "    # Check 2: Duplicaten\n",
    "    duplicates = df.duplicated(subset=['sensor_id', 'timestamp']).sum()\n",
    "    if duplicates > 0:\n",
    "        warnings.append(f\"{duplicates} duplicate records gevonden (zullen worden verwijderd)\")\n",
    "    \n",
    "    # Check 3: Data coverage - elke sensor heeft data?\n",
    "    sensor_counts = df.groupby('sensor_id').size()\n",
    "    low_coverage = sensor_counts[sensor_counts < 5]\n",
    "    if len(low_coverage) > 0:\n",
    "        warnings.append(f\"Lage data coverage voor: {low_coverage.to_dict()}\")\n",
    "    \n",
    "    # Check 4: Waarde ranges per sensor type\n",
    "    temp_out_of_range = df[(df['sensor_type'] == 'TEMP') & ~df['value'].between(15, 30)]\n",
    "    co2_high = df[(df['sensor_type'] == 'CO2') & (df['value'] > 1000)]\n",
    "    \n",
    "    if len(temp_out_of_range) > 0:\n",
    "        warnings.append(f\"{len(temp_out_of_range)} temperatuur waarden buiten comfortzone (15-30 graden C)\")\n",
    "    if len(co2_high) > 0:\n",
    "        warnings.append(f\"{len(co2_high)} CO2 waarden > 1000 ppm (slechte luchtkwaliteit!)\")\n",
    "    \n",
    "    # Check 5: Tijdsgaten (missende metingen)\n",
    "    df_sorted = df.sort_values(['sensor_id', 'timestamp'])\n",
    "    for sensor_id in df['sensor_id'].unique():\n",
    "        sensor_data = df_sorted[df_sorted['sensor_id'] == sensor_id]\n",
    "        if len(sensor_data) > 1:\n",
    "            time_diffs = sensor_data['timestamp'].diff()\n",
    "            large_gaps = time_diffs[time_diffs > timedelta(hours=1)]\n",
    "            if len(large_gaps) > 0:\n",
    "                warnings.append(f\"{sensor_id}: {len(large_gaps)} tijdsgaten > 1 uur\")\n",
    "    \n",
    "    # Print rapport\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATA QUALITY RAPPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not issues and not warnings:\n",
    "        print(\"[OK] Alle validaties geslaagd!\")\n",
    "        return True\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\n[KRITIEKE ISSUES]\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(\"\\n[WAARSCHUWINGEN]\")\n",
    "        for warning in warnings:\n",
    "            print(f\"  - {warning}\")\n",
    "    \n",
    "    # Tolerantieniveau: geen kritieke issues, waarschuwingen zijn OK\n",
    "    is_valid = len(issues) == 0\n",
    "    print(f\"\\n[INFO] Data {'geaccepteerd' if is_valid else 'AFGEKEURD'}\")\n",
    "    print(f\"Tolerantieniveau: geen kritieke issues toegestaan\")\n",
    "    \n",
    "    return is_valid\n",
    "\n",
    "# Validate\n",
    "is_valid = validate_data(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Loading - Waar en hoe sla je de data op?\n",
    "\n",
    "Schrijf de gevalideerde data naar de target database/storage.\n",
    "\n",
    "**Parquet vs CSV:**\n",
    "- CSV: Row-based, makkelijk leesbaar, groot\n",
    "- Parquet: Column-based, gecomprimeerd, snel voor analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid = True  # Forceer validatie voor demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestaande data gevonden: 52 records\n",
      "52 duplications verwijderd\n",
      "\n",
      "52 nieuwe records opgeslagen\n",
      "Totaal in warehouse: 52 records\n",
      "\n",
      "File sizes:\n",
      "  CSV: 5.3 KB\n",
      "  Parquet: 9.1 KB\n",
      "\n",
      "[WAARSCHUWING] Parquet bestand is groter dan CSV. Rule-of-thumb: gebruik CSV bij minder dan ≈1,000 records.\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"sensor_data_warehouse.csv\"\n",
    "OUTPUT_PARQUET = \"sensor_data_warehouse.parquet\"\n",
    "\n",
    "def load_data(df):\n",
    "    \"\"\"Laad data naar target (CSV en Parquet)\"\"\"\n",
    "    # In productie: df.to_sql('sensor_readings', con=db_engine, if_exists='append')\n",
    "    \n",
    "    try:\n",
    "        # Append to existing file\n",
    "        existing_df = pd.read_csv(OUTPUT_FILE)\n",
    "        existing_df['timestamp'] = pd.to_datetime(existing_df['timestamp'])\n",
    "        combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        print(f\"Bestaande data gevonden: {len(existing_df)} records\")\n",
    "    except FileNotFoundError:\n",
    "        combined_df = df\n",
    "        print(\"Nieuwe data warehouse aangemaakt\")\n",
    "    \n",
    "    # Verwijder duplicaten\n",
    "    before_dedup = len(combined_df)\n",
    "    combined_df = combined_df.drop_duplicates(subset=['sensor_id', 'timestamp'])\n",
    "    after_dedup = len(combined_df)\n",
    "    \n",
    "    print(f\"{before_dedup - after_dedup} duplications verwijderd\")\n",
    "    \n",
    "    # Save als CSV (row-based)\n",
    "    combined_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    csv_size = Path(OUTPUT_FILE).stat().st_size / 1024  # KB\n",
    "    \n",
    "    # Save als Parquet (column-based, beter voor analytics)\n",
    "    combined_df.to_parquet(OUTPUT_PARQUET, index=False, engine='pyarrow')\n",
    "    parquet_size = Path(OUTPUT_PARQUET).stat().st_size / 1024  # KB\n",
    "    \n",
    "    print(f\"\\n{len(df)} nieuwe records opgeslagen\")\n",
    "    print(f\"Totaal in warehouse: {len(combined_df)} records\")\n",
    "    print(f\"\\nFile sizes:\")\n",
    "    print(f\"  CSV: {csv_size:.1f} KB\")\n",
    "    print(f\"  Parquet: {parquet_size:.1f} KB\")\n",
    "\n",
    "    if parquet_size > csv_size:\n",
    "        print(\"\\n[WAARSCHUWING] Parquet bestand is groter dan CSV. \" \\\n",
    "        \"Rule-of-thumb: gebruik CSV bij minder dan ≈1,000 records.\")\n",
    "    \n",
    "    return len(df)\n",
    "\n",
    "# Load (alleen als validatie OK is)\n",
    "if is_valid:\n",
    "    records_loaded = load_data(transformed_data)\n",
    "else:\n",
    "    print(\"[FOUT] Data niet geladen vanwege validatie fouten\")\n",
    "    records_loaded = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Archiving and Retention - Hoe lang bewaar je data?\n",
    "\n",
    "Implementeer een retention policy: verwijder data ouder dan X dagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alle data binnen retention period (90 dagen)\n",
      "Oudste record: 2025-10-14 08:00:00\n"
     ]
    }
   ],
   "source": [
    "def apply_retention_policy(retention_days=90):\n",
    "    \"\"\"Verwijder data ouder dan retention period\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(OUTPUT_FILE)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        cutoff_date = datetime.now() - timedelta(days=retention_days)\n",
    "        \n",
    "        # Filter data binnen retention period\n",
    "        df_retained = df[df['timestamp'] >= cutoff_date]\n",
    "        df_archived = df[df['timestamp'] < cutoff_date]\n",
    "        \n",
    "        if len(df_archived) > 0:\n",
    "            # In productie: verplaats naar archive storage (S3 Glacier, etc.)\n",
    "            archive_file = f\"archive_{cutoff_date.date()}.csv\"\n",
    "            df_archived.to_csv(archive_file, index=False)\n",
    "            df_retained.to_csv(OUTPUT_FILE, index=False)\n",
    "            \n",
    "            print(f\"{len(df_archived)} oude records gearchiveerd naar {archive_file}\")\n",
    "            print(f\"{len(df_retained)} records behouden (< {retention_days} dagen oud)\")\n",
    "            print(f\"Oudste record: {df_retained['timestamp'].min()}\")\n",
    "            print(f\"Nieuwste record: {df_retained['timestamp'].max()}\")\n",
    "        else:\n",
    "            print(f\"Alle data binnen retention period ({retention_days} dagen)\")\n",
    "            print(f\"Oudste record: {df['timestamp'].min()}\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"Geen data om te archiveren\")\n",
    "\n",
    "# Apply retention (90 dagen)\n",
    "apply_retention_policy(retention_days=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pipeline Afronden - Update State\n",
    "\n",
    "Sla de nieuwe pipeline state op voor de volgende run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State opgeslagen\n",
      "\n",
      "============================================================\n",
      "PIPELINE SUCCESVOL AFGEROND\n",
      "============================================================\n",
      "Totaal verwerkte records deze run: 52\n",
      "Totaal verwerkte records (lifetime): 52\n",
      "Totaal verwerkte files: 2\n"
     ]
    }
   ],
   "source": [
    "# Update pipeline state\n",
    "if is_valid:\n",
    "    pipeline_state['last_run'] = datetime.now().isoformat()\n",
    "    pipeline_state['records_processed'] += records_loaded\n",
    "    \n",
    "    # Voeg verwerkte files toe\n",
    "    new_file_names = [f.name for f in (new_files if new_files else files_to_process[:1])]\n",
    "    pipeline_state['processed_files'].extend(new_file_names)\n",
    "    \n",
    "    save_state(pipeline_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE SUCCESVOL AFGEROND\" if is_valid else \"PIPELINE AFGEBROKEN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Totaal verwerkte records deze run: {records_loaded}\")\n",
    "print(f\"Totaal verwerkte records (lifetime): {pipeline_state['records_processed']}\")\n",
    "print(f\"Totaal verwerkte files: {len(pipeline_state['processed_files'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Check nieuwe state\n",
    "Run nu nog een keer de code van het blok \"3. State Management\" en je ziet dat er geen nieuwe files meer te verwerken zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
